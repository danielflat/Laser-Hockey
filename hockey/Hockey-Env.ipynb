{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import hockey.hockey_env as h_env"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.set_printoptions(suppress = True)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "reload(h_env)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Normal Game Play"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = h_env.HockeyEnv()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "have a look at the initialization condition: alternating who starts and are random in puck position"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs, info = env.reset()\n",
    "obs_agent2 = env.obs_agent_two()\n",
    "_ = env.render()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "one episode with random agents"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs, info = env.reset()\n",
    "obs_agent2 = env.obs_agent_two()\n",
    "\n",
    "for _ in range(600):\n",
    "    env.render(mode = \"human\")\n",
    "    a1 = np.random.uniform(-1, 1, 4)\n",
    "    a2 = np.random.uniform(-1, 1, 4)\n",
    "    obs, r, d, t, info = env.step(np.hstack([a1, a2]))\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Without rendering, it runs much faster"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "\"info\" dict contains useful proxy rewards and winning information"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "info, env.get_info_agent_two()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Winner == 0: draw\n",
    "\n",
    "Winner == 1: you (left player)\n",
    "\n",
    "Winner == -1: opponent wins (right player)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env.close()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Shooting"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = h_env.HockeyEnv(mode = h_env.HockeyEnv.TRAIN_SHOOTING)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "o, info = env.reset()\n",
    "_ = env.render()\n",
    "\n",
    "for _ in range(50):\n",
    "    env.render()\n",
    "    a1 = [1, 0, 0, 1]  # np.random.uniform(-1,1,4)\n",
    "    a2 = [0, 0., 0, 0]\n",
    "    obs, r, d, t, info = env.step(np.hstack([a1, a2]))\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env.close()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train DEFENDING"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = h_env.HockeyEnv(mode = h_env.HockeyEnv.TRAIN_DEFENSE)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "o, info = env.reset()\n",
    "_ = env.render()\n",
    "\n",
    "for _ in range(60):\n",
    "    env.render()\n",
    "    a1 = [0.1, 0, 0, 1]  # np.random.uniform(-1,1,3)\n",
    "    a2 = [0, 0., 0, 0]\n",
    "    obs, r, d, t, info = env.step(np.hstack([a1, a2]))\n",
    "    print(r)\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env.close()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Using discrete actions"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import random"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = h_env.HockeyEnv(mode = h_env.HockeyEnv.TRAIN_SHOOTING)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "env.reset()\n",
    "for _ in range(251):\n",
    "    env.render()\n",
    "    a1_discrete = random.randint(0, 7)\n",
    "    a1 = env.discrete_to_continous_action(a1_discrete)\n",
    "    a2 = [0, 0., 0, 0]\n",
    "    obs, r, d, t, info = env.step(np.hstack([a1, a2]))\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env.close()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hand-crafted Opponent"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = h_env.HockeyEnv()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "o, info = env.reset()\n",
    "_ = env.render()\n",
    "player1 = h_env.BasicOpponent(weak = False)\n",
    "player2 = h_env.BasicOpponent()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs_buffer = []\n",
    "reward_buffer = []\n",
    "obs, info = env.reset()\n",
    "obs_agent2 = env.obs_agent_two()\n",
    "for _ in range(251):\n",
    "    env.render()\n",
    "    a1 = player1.act(obs)\n",
    "    a2 = player2.act(obs_agent2)\n",
    "    obs, r, d, t, info = env.step(np.hstack([a1, a2]))\n",
    "    obs_buffer.append(obs)\n",
    "    reward_buffer.append(r)\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d or t: break\n",
    "obs_buffer = np.asarray(obs_buffer)\n",
    "reward_buffer = np.asarray(reward_buffer)\n",
    "reward_buffer"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.mean(obs_buffer, axis = 0)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.std(obs_buffer, axis = 0)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If you want to use a fixed observation scaling, this might be a reasonable choice"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scaling = [1.0, 1.0, 0.5, 4.0, 4.0, 4.0,\n",
    "           1.0, 1.0, 0.5, 4.0, 4.0, 4.0,\n",
    "           2.0, 2.0, 10.0, 10.0, 4, 0, 4, 0]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import matplotlib.pyplot as plt  # df: Changed from pylab, since its usage is deprecated"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(obs_buffer[:, 2])\n",
    "plt.plot(obs_buffer[:, 8])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.plot(obs_buffer[:, 12])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plt.plot(reward_buffer[:])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.sum(reward_buffer)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "info2 = env.get_info_agent_two()\n",
    "info, info2, env.get_reward(info), env.get_reward_agent_two(info2)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env.close()"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Human Opponent"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = h_env.HockeyEnv()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "player1 = h_env.HumanOpponent(env = env, player = 1)\n",
    "player2 = h_env.BasicOpponent()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "player1 = h_env.BasicOpponent()\n",
    "player2 = h_env.HumanOpponent(env = env, player = 2)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs, info = env.reset()\n",
    "\n",
    "env.render()\n",
    "time.sleep(1)\n",
    "obs_agent2 = env.obs_agent_two()\n",
    "for _ in range(100):\n",
    "    time.sleep(0.2)\n",
    "    env.render()\n",
    "    a1 = player1.act(obs)\n",
    "    a2 = player2.act(obs_agent2)\n",
    "    obs, r, d, _, info = env.step(np.hstack([a1, a2]))\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    if d: break"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env.close()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Check side consistency"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env = h_env.HockeyEnv()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "o, info = env.reset()\n",
    "_ = env.render()\n",
    "player1 = h_env.BasicOpponent(weak = False)\n",
    "player2 = h_env.BasicOpponent(weak = False)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs_buffer = []\n",
    "reward_buffer = []\n",
    "obs2_buffer = []\n",
    "winner_buffer = []\n",
    "reward2_buffer = []\n",
    "for game in range(1000):\n",
    "    obs, info = env.reset()\n",
    "    obs_agent2 = env.obs_agent_two()\n",
    "    for _ in range(500):\n",
    "        # env.render()\n",
    "        a1 = player1.act(obs)\n",
    "        a2 = player2.act(obs_agent2)\n",
    "        #        a1 = np.random.uniform(-1,1,4)\n",
    "        #        a2 = np.random.uniform(-1,1,4)\n",
    "        obs, r, d, t, info = env.step(np.hstack([a1, a2]))\n",
    "        info2 = env.get_info_agent_two()\n",
    "        r2 = env.get_reward_agent_two(info2)\n",
    "        obs_buffer.append(obs)\n",
    "        obs_agent2 = env.obs_agent_two()\n",
    "        obs2_buffer.append(obs_agent2)\n",
    "        reward_buffer.append(r)\n",
    "        reward2_buffer.append(r2)\n",
    "        if d or t:\n",
    "            winner_buffer.append(info[\"winner\"])\n",
    "            break\n",
    "obs_buffer = np.asarray(obs_buffer)\n",
    "reward_buffer = np.asarray(reward_buffer)\n",
    "obs2_buffer = np.asarray(obs2_buffer)\n",
    "reward2_buffer = np.asarray(reward2_buffer)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "obs_buffer.shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.mean(obs_buffer, axis = 0)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "(np.std(obs_buffer, axis = 0) - np.std(obs2_buffer, axis = 0)) / np.std(obs_buffer, axis = 0)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "winner_buffer"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.mean(winner_buffer, axis = 0)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.std(winner_buffer, axis = 0)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "np.sum(reward_buffer), np.sum(reward2_buffer)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "env.close()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
